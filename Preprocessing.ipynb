{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"jupy_code_ocr.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"N2CsCFeeokGh","colab_type":"code","colab":{},"outputId":"c3dbb068-9a26-44b5-aef5-12f4cda1b8dc"},"cell_type":"code","source":["\"\"\"\n","@author: SHREEKANTH\n","\"\"\"\n","import cv2\n","import math\n","import imutils\n","import numpy as np\n","\n","img = cv2.imread(r'C:\\Users\\SHREEKANTH\\Desktop\\scan2.jpg')\n","\n","img1 = img [:int(img.shape[0]/3),:int(img.shape[1]/2)]\n","img2 = img [:int(img.shape[0]/3),int(img.shape[1]/2):int(img.shape[1])-1]\n","#cv2.imshow('IMG1',img1)\n","#cv2.waitKey(0)\n","#cv2.imshow('IMG2',img2)\n","#cv2.waitKey(0)\n","\n","# Apply template Matching\n","\n","img3 = img.copy()\n","template = cv2.imread(r'C:\\Users\\SHREEKANTH\\Desktop\\template.jpg')\n","w=template.shape[0]\n","h=template.shape[1]\n","\n","left_box = cv2.matchTemplate(img1,template,cv2.TM_SQDIFF)\n","min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(left_box)\n","top_left1 = min_loc\n","bottom_right1 = (top_left1[0] + w, top_left1[1] + h)\n","print('Initial top left box' , top_left1,bottom_right1)\n","\n","\n","right_box = cv2.matchTemplate(img2,template,cv2.TM_SQDIFF)\n","min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(right_box)\n","top_left2 = min_loc\n","bottom_right2 = (top_left2[0] + w, top_left2[1] + h)\n","print('Initial top right box',top_left2,bottom_right2)\n","\n","#To rotate the image\n","t1 = top_left2[1] - top_left1[1]\n","t2 = int(img.shape[1]/2) + top_left2[0] - top_left1[0]\n","angle = np.arctan2(t1,t2)\n","angle = math.degrees(angle)\n","print('Angle to be rotated',angle)\n","            \n","rotated = imutils.rotate(img, angle)\n","#cv2.imshow('rot',rotated)\n","#cv2.waitKey(0)\n","\n","img = rotated.copy()\n","cv2.imwrite('rot.jpg',img)\n","\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","ret,thresh = cv2.threshold(gray,175,255,cv2.THRESH_BINARY)\n","\n","for j in range(thresh.shape[1]-int(img.shape[1]/2)-top_left2[0]):\n","    px = thresh[(top_left2[1]-60),(int(img.shape[1]/2)+top_left2[0]+j)]\n","#    print(px,(top_left2[1]-60),(int(img.shape[1]/2)+top_left2[0]+j))\n","    if px == 255:\n","        break;\n","\n","print('Left side cropping factors', int(img.shape[1]/2)+top_left2[0]+j , j)\n","  \n","img3 = img[:int(img.shape[1]/3),:int(img.shape[0]/2)]\n","left_box = cv2.matchTemplate(img3,template,cv2.TM_SQDIFF)\n","min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(left_box)\n","top_left1 = min_loc\n","bottom_right1 = (top_left1[0] + w, top_left1[1] + h)\n","print('After rotation top left box' , top_left1,bottom_right1)\n","\n","img4 = img[int(2*img.shape[0]/3):,:int(img.shape[0]/2)]\n","bottom_left_box = cv2.matchTemplate(img4,template,cv2.TM_SQDIFF)\n","min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(bottom_left_box)\n","top_left3 = min_loc\n","bottom_right3 = (top_left3[0] + w, top_left3[1] + h)\n","print('After rotation bottom most left box' , top_left3,bottom_right3)\n","\n","bottom_crop = int(2*img.shape[0]/3) + bottom_right3[1] + 41  #41 is correction value\n","print('Bottom cropping factor',bottom_crop)\n","\n","dim = (img.shape[1] , 2339)\n","cut_img = img[:bottom_crop,]\n","img = cv2.resize(cut_img, dim, interpolation = cv2.INTER_AREA)\n","cv2.imwrite('bot.jpg',img)\n","\n","cut_img = img[(top_left1[1]-127):,: int(img.shape[1]/2)+top_left2[0]+j]\n","print('After croping size' , cut_img.shape)\n","\n","if top_left1[0] <=20 :\n","    add = cv2.imread(r'C:\\Users\\SHREEKANTH\\Desktop\\add_on.jpg')\n","    ver = add[0:cut_img.shape[0],0:(20-top_left1[0])]\n","    to_resize = np.concatenate((ver,cut_img), axis=1)\n","else :\n","    to_resize = cut_img[ :cut_img.shape[0], (top_left1[0]-20):]\n","    \n","print('After concatenation if req',to_resize.shape)\n","#cv2.imshow('to_re',to_resize)\n","#cv2.waitKey(0)\n","\n","dim = (1654,2339)\n","fin_img = cv2.resize(to_resize, dim, interpolation = cv2.INTER_AREA)\n","\n","#l = fin_img[209:248,610:649]\n","#cv2.imshow('l',l)\n","#cv2.waitKey(0)\n","\n","print('Final resized shape' , fin_img.shape)\n","#cv2.imshow('fin_img',fin_img)\n","#cv2.waitKey(0)\n","cv2.imwrite('fin.jpg',fin_img)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Initial top left box (52, 129) (89, 166)\n","Initial top right box (731, 141) (768, 178)\n","Angle to be rotated 0.4496633342560517\n","Left side cropping factors 1631 50\n","After rotation top left box (44, 135) (81, 172)\n","After rotation bottom most left box (47, 646) (84, 683)\n","Bottom cropping factor 2282\n","After croping size (2331, 1631, 3)\n","After concatenation if req (2331, 1607, 3)\n","Final resized shape (2339, 1654, 3)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"--3IlbbgokGo","colab_type":"code","colab":{},"outputId":"3c74cf28-c248-4817-d148-86f0f70d64fd"},"cell_type":"code","source":["from keras.models import load_model\n","alpha_num=load_model(r'C:\\Users\\SHREEKANTH\\Desktop\\OCR\\alphanum2.model')\n","alpha_num.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","alpha=load_model(r'C:\\Users\\SHREEKANTH\\Desktop\\OCR\\ocr.model')\n","alpha.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","numbers=load_model(r'C:\\Users\\SHREEKANTH\\Desktop\\OCR\\num.model')\n","numbers.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","alphabets = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O',\n","            'P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9']\n","\n","s=\"\"\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["I:\\Anaco\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  from ._conv import register_converters as _register_converters\n","Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"PJ0MJNcVokGv","colab_type":"code","colab":{},"outputId":"beded8ea-7ddf-42e8-fedd-e468191ab00f"},"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv(r'C:\\Users\\SHREEKANTH\\Desktop\\OCR\\coordinates2.csv')\n","\n","tags = df.columns.tolist()\n","\n","list1 = []  #field contains numbers only\n","list2 = []  #field contains charcters only\n","list3 = []  #field contains both\n","\n","print('1.Number 2.Charcter 3.AlphaNumerical')\n","\n","for tag in tags:\n","    print(tag)\n","    choice = int(input('Enter'))\n","    \n","    if choice == 1:\n","        list1.append(tag)\n","    elif choice == 2:\n","        list2.append(tag)\n","    elif choice == 3 :\n","        list3.append(tag)\n","\n","print('Number Fields',list1)\n","print('Alphabet Fields',list2)\n","print('Alphanumerical Fields',list3)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.Number 2.Charcter 3.AlphaNumerical\n","Employee Code\n","Enter3\n","OPTY ID\n","Enter2\n","TITLE\n","Enter2\n","NAME\n","Enter2\n","Maiden Name\n","Enter2\n","Mothers Maiden Name\n","Enter2\n","LINE 1\n","Enter3\n","LINE 2\n","Enter3\n","LINE 3\n","Enter3\n","CITY\n","Enter2\n","STATE\n","Enter2\n","Pincode\n","Enter1\n","Telephone No\n","Enter1\n","DOB\n","Enter1\n","Father/Spouse Name\n","Enter2\n","Preferred Mobile Number\n","Enter1\n","Number Fields ['Pincode', 'Telephone No', 'DOB', 'Preferred Mobile Number']\n","Alphabet Fields ['OPTY ID', 'TITLE', 'NAME', 'Maiden Name', 'Mothers Maiden Name', 'CITY', 'STATE', 'Father/Spouse Name']\n","Alphanumerical Fields ['Employee Code', 'LINE 1', 'LINE 2', 'LINE 3']\n"],"name":"stdout"}]},{"metadata":{"id":"q2Qq8DDdokGy","colab_type":"code","colab":{},"outputId":"21142006-845f-4f34-e9e9-620332953dc2"},"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv(r'C:\\Users\\SHREEKANTH\\Desktop\\OCR\\coordinates2.csv')\n","\n","tags = df.columns.tolist()\n","\n","for tag in tags:\n","    x = df[tag].tolist()\n","    y1 = int(x[0])\n","    y2 = int(x[1])\n","    x = x[2:]\n","    ind = x.index(max(x))\n","    x = x[:ind+1]\n","    x = [round(y) for y in x]\n","    z = 0\n","    \n","    \n","    for i in range(len(x)-1):\n","        character = fin_img[y1:y2,x[i]:x[i+1]]\n","        ret,character = cv2.threshold(character,230,255,cv2.THRESH_BINARY_INV)\n","        #cv2.imshow('Letter',character)\n","        #cv2.waitKey(0)\n","        #  Resizing the charcacter to 28x28 to pass it the model\n","        dim = (28,28)\n","        letter = cv2.resize(character, dim, interpolation = cv2.INTER_AREA)\n","        letter = cv2.cvtColor(letter,cv2.COLOR_BGR2GRAY)    \n","        \n","        if cv2.countNonZero(letter) == 0 :\n","            if z!=1:\n","                s = s + \" \"\n","                z = 1\n","            else :\n","                break; \n","        else:\n","            x1 = np.array(letter)\n","            x1 = x1/255\n","            x1 = x1.reshape(1,28,28,1)\n","            if list1.__contains__(tag):\n","                classes = numbers.predict_classes(x1)\n","                s = s + alphabets[26+classes[0]]\n","            elif list2.__contains__(tag):\n","                classes = alpha.predict_classes(x1)\n","                s = s + alphabets[classes[0]]\n","            else :\n","                classes = alpha_num.predict_classes(x1)\n","                s = s + alphabets[classes[0]]\n","            z = 0\n","    \n","    print(tag,':',s)\n","    s=\"\"\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Employee Code : NU2MNE\n","OPTY ID : ARCDRKGHNTKL\n","TITLE : MR\n","NAME : KHREEKANTH RAGHNNATKXN \n","Maiden Name :  \n","Mothers Maiden Name :  \n","LINE 1 : 189FBGJ \n","LINE 2 : TYPEE3 QKTS5 \n","LINE 3 : 8L0CKS5 7 \n","CITY : NEYNELI \n","STATE : TAMTL NADN \n","Pincode : 607101\n","Telephone No :  \n","DOB : 78101490\n","Father/Spouse Name :  \n","Preferred Mobile Number : 1707160605\n"],"name":"stdout"}]},{"metadata":{"id":"vrSAkJ0ZokG3","colab_type":"code","colab":{},"outputId":"7afc21c5-c6af-4108-9db8-6629db16bcdb"},"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv(r'C:\\Users\\SHREEKANTH\\Desktop\\OCR\\tick_box1.csv')\n","df = df.dropna()\n","\n","tags = df.columns.tolist()\n","\n","for tag in tags:\n","    x = df[tag].tolist()\n","    y1 = int(x[0])\n","    y2 = int(x[1])\n","    x = x[2:]\n","    i = 1\n","    \n","    while( i < len(x) ):\n","        character = fin_img[y1:y2,int(x[i]):int(x[i+1])]\n","        ret,character = cv2.threshold(character,230,255,cv2.THRESH_BINARY_INV)\n","        #cv2.imshow('Letter',character)\n","        #cv2.waitKey(0)\n","        dim = (28,28)\n","        letter = cv2.resize(character, dim, interpolation = cv2.INTER_AREA)\n","        letter = cv2.cvtColor(letter,cv2.COLOR_BGR2GRAY)    \n","        \n","        if cv2.countNonZero(letter) != 0 :\n","            s = s + x[i-1] + \" \"\n","        i = i + 3\n","    \n","    print(tag,':',s)\n","    s=\"\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Purpose : Current Account \n","Group : \n","Residential Status : Residential Indian \n","Citizenship : \n","Religion : Hindu \n","Category : General \n","Education : \n","Gender : Male \n","Marital Status : \n","Annual Income : 0 - 2 Lakhs \n"],"name":"stdout"}]},{"metadata":{"id":"V0JouGP4okG7","colab_type":"code","colab":{},"outputId":"a10e6e81-2114-4ea5-de04-7f0c7acef0a1"},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import cv2\n","fin_img = cv2.imread(r'C:\\Users\\SHREEKANTH\\Desktop\\OCR\\fin.jpg')\n","\n","character = fin_img[474:505,248:281]\n","ret,character = cv2.threshold(character,230,255,cv2.THRESH_BINARY_INV)\n","#cv2.imshow('Letter',character)\n","#cv2.waitKey(0)\n","#  Resizing the charcacter to 28x28 to pass it the model\n","dim = (100,100)\n","letter = cv2.resize(character, dim, interpolation = cv2.INTER_AREA)\n","letter = cv2.cvtColor(letter,cv2.COLOR_BGR2GRAY)    \n","plt.imshow(letter,cmap='gray')        \n","\n","#x1 = np.array(letter)\n","#x1 = x1/255\n","#x1 = x1.reshape(1,28,28,1)\n","#classes = model.predict_classes(x1)\n","#print(alphabet[classes[0]])\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x216ace30470>"]},"metadata":{"tags":[]},"execution_count":39},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<matplotlib.figure.Figure at 0x216acdeae80>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"y_iBRPn7okG-","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv(r'C:\\Users\\SHREEKANTH\\Desktop\\OCR\\coordinates2.csv')\n","\n","tags = df.columns.tolist()\n","\n","tag = 'NAME'\n","\n","x = df[tag].tolist()\n","y1 = int(x[0])\n","y2 = int(x[1])\n","x = x[2:]\n","ind = x.index(max(x))\n","x = x[:ind+1]\n","x = [round(y) for y in x]\n","z = 0\n","    \n","for i in range(len(x)-1):\n","    #cv2.imshow('Letter',character)\n","    #gray_image = cv2.cvtColor(fin_img, cv2.COLOR_BGR2GRAY)\n","    character = fin_img[y1:y2,x[i]:x[i+1]]\n","    cv2.imshow('Letter',character)\n","    ret,character = cv2.threshold(character,230,255,cv2.THRESH_BINARY_INV)\n","    #character = cv2.adaptiveThreshold(character,255,1,1,11,2)\n","    cv2.imshow('Letter',character)\n","    cv2.waitKey(0)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XvbTh4LPokHA","colab_type":"code","colab":{},"outputId":"80e45ce7-8b81-497d-91bf-9b83008b3713"},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","df = pd.read_csv(r'C:\\Users\\SHREEKANTH\\Desktop\\number.csv')\n","\n","tags = df.columns.tolist()\n","\n","x = df['one'].tolist()\n","print(x)\n","\n","a = np.array(x)\n","print(type(a))\n","\n","a = np.resize(a,(28,28))\n","print(a.shape)\n","\n","cv2.imshow('one',a)\n","cv2.waitKey(0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 188, 255, 94, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 191, 250, 253, 93, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 123, 248, 253, 167, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 80, 247, 253, 208, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29, 207, 253, 235, 77, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54, 209, 253, 253, 88, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 93, 254, 253, 238, 170, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 210, 254, 253, 159, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 209, 253, 254, 240, 81, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27, 253, 253, 254, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 206, 254, 254, 198, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 168, 253, 253, 196, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 203, 253, 248, 76, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 188, 253, 245, 93, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 103, 253, 253, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 89, 240, 253, 195, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 220, 253, 253, 80, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 94, 253, 253, 253, 94, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 89, 251, 253, 250, 131, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 214, 218, 95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","<class 'numpy.ndarray'>\n","(28, 28)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["-1"]},"metadata":{"tags":[]},"execution_count":37}]}]}